{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a92e073",
   "metadata": {},
   "source": [
    "This notebook is for creating the base ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f4398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf78bb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['#', 'datetime', 'location', 'busyness'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_2021-22-23-24.csv')\n",
    "df.drop('Zone', axis=1, inplace=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed47a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>datetime</th>\n",
       "      <th>location</th>\n",
       "      <th>busyness</th>\n",
       "      <th>Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Alphabet City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Arden Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrochar/Fort Wadsworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Astoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #             datetime  location  busyness                     Zone\n",
       "0  1  2021-01-01 00:00:00         3         1  Allerton/Pelham Gardens\n",
       "1  2  2021-01-01 00:00:00         4         1            Alphabet City\n",
       "2  3  2021-01-01 00:00:00         5         1            Arden Heights\n",
       "3  4  2021-01-01 00:00:00         6         1  Arrochar/Fort Wadsworth\n",
       "4  5  2021-01-01 00:00:00         7         1                  Astoria"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fe3868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#            int64\n",
      "datetime    object\n",
      "location     int64\n",
      "busyness     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'zone' column\n",
    "df = df.drop(columns=['Zone'])\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd5045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    #  busyness\n",
      "item_id timestamp              \n",
      "3       2021-01-01  1         1\n",
      "4       2021-01-01  2         1\n",
      "5       2021-01-01  3         1\n",
      "6       2021-01-01  4         1\n",
      "7       2021-01-01  5         1\n"
     ]
    }
   ],
   "source": [
    "data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"location\",\n",
    "    timestamp_column=\"datetime\"\n",
    ")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 3 * 30 * 24 # 3 months prediction window\n",
    "train_data, test_data = data.train_test_split(prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b2e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon-m4-hourly\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we made the predictor\n"
     ]
    }
   ],
   "source": [
    "# setting the frequency to h since the data is grouped/collected hourly,\n",
    "# # added relative path \n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    freq='h',\n",
    "    target=\"busyness\"\n",
    "    eval_metric=\"MASE\",\n",
    "    prediction_length=pred_len,\n",
    "    path=\"base_model\"\n",
    ")\n",
    "print('we made the predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89eac65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>busyness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <th>2021-08-22 02:00:00</th>\n",
       "      <td>1436530</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <th>2024-01-16 00:00:00</th>\n",
       "      <td>6850674</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <th>2021-12-22 00:00:00</th>\n",
       "      <td>2188890</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <th>2022-10-27 02:00:00</th>\n",
       "      <td>4096784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <th>2021-08-30 19:00:00</th>\n",
       "      <td>1490420</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   # busyness\n",
       "item_id timestamp                            \n",
       "63      2021-08-22 02:00:00  1436530     None\n",
       "90      2024-01-16 00:00:00  6850674     None\n",
       "74      2021-12-22 00:00:00  2188890     None\n",
       "176     2022-10-27 02:00:00  4096784     None\n",
       "182     2021-08-30 19:00:00  1490420     None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating a sample of the train data for testing\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "test = train_data.sample(n=subsample_size, random_state=0)\n",
    "test['busyness'] = None\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0da2a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Found no cached predictions\n",
      "Prediction order: ['TemporalFusionTransformer', 'SeasonalNaive', 'WeightedEnsemble']\n",
      "Predicting with model TemporalFusionTransformer/W0\n",
      "Predicting with model TemporalFusionTransformer\n",
      "Shortening all time series to at most 2500\n",
      "Predicting with model SeasonalNaive/W0\n",
      "Predicting with model SeasonalNaive\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to autogluon-m4-hourly/models/cached_predictions.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 mean       0.1       0.2       0.3       0.4  \\\n",
      "item_id timestamp                                                               \n",
      "54      2022-07-20 11:00:00  0.024499  0.016303  0.017815  0.019523  0.020714   \n",
      "        2022-07-20 12:00:00  0.024575  0.016121  0.017457  0.019211  0.020482   \n",
      "        2022-07-20 13:00:00  0.024608  0.015974  0.017147  0.018884  0.020198   \n",
      "        2022-07-20 14:00:00  0.024587  0.015869  0.016932  0.018638  0.019950   \n",
      "        2022-07-20 15:00:00  0.024564  0.015777  0.016758  0.018443  0.019722   \n",
      "...                               ...       ...       ...       ...       ...   \n",
      "111     2022-04-13 15:00:00  0.024573  0.015634  0.016650  0.018291  0.019699   \n",
      "        2022-04-13 16:00:00  0.024597  0.015592  0.016543  0.018142  0.019488   \n",
      "        2022-04-13 17:00:00  0.024583  0.015589  0.016483  0.018065  0.019333   \n",
      "        2022-04-13 18:00:00  0.024509  0.015601  0.016434  0.018030  0.019237   \n",
      "        2022-04-13 19:00:00  0.024395  0.015592  0.016340  0.017971  0.019157   \n",
      "\n",
      "                                  0.5       0.6       0.7       0.8       0.9  \n",
      "item_id timestamp                                                              \n",
      "54      2022-07-20 11:00:00  0.021850  0.022534  0.022324  0.022489  0.042282  \n",
      "        2022-07-20 12:00:00  0.021926  0.022664  0.022301  0.022442  0.042431  \n",
      "        2022-07-20 13:00:00  0.021959  0.022743  0.022250  0.022447  0.042606  \n",
      "        2022-07-20 14:00:00  0.021938  0.022779  0.022196  0.022474  0.042748  \n",
      "        2022-07-20 15:00:00  0.021915  0.022811  0.022195  0.022566  0.042939  \n",
      "...                               ...       ...       ...       ...       ...  \n",
      "111     2022-04-13 15:00:00  0.021924  0.022704  0.022047  0.022307  0.042294  \n",
      "        2022-04-13 16:00:00  0.021948  0.022778  0.022093  0.022424  0.042518  \n",
      "        2022-04-13 17:00:00  0.021934  0.022835  0.022172  0.022556  0.042759  \n",
      "        2022-04-13 18:00:00  0.021860  0.022840  0.022199  0.022616  0.042873  \n",
      "        2022-04-13 19:00:00  0.021746  0.022774  0.022160  0.022600  0.042855  \n",
      "\n",
      "[10512 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51d0a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  #  busyness            Zone\n",
      "item_id timestamp                                            \n",
      "265     2024-03-31 23:00:00  370374         2  Outside of NYC\n",
      "79      2024-04-01 00:00:00  370375         1    East Village\n",
      "90      2024-04-01 00:00:00  370376         1        Flatiron\n",
      "107     2024-04-01 00:00:00  370377         1        Gramercy\n",
      "163     2024-04-01 00:00:00  370378         1   Midtown North\n"
     ]
    }
   ],
   "source": [
    "# update the path for github\n",
    "df1 = pd.read_csv('test_2024_04_03_02.csv')\n",
    "\n",
    "#making sure there are no duplicates\n",
    "df1 = df1.drop_duplicates()\n",
    "\n",
    "# making sure formatting is correct\n",
    "df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "# Replace all values in the 'busyness' column with NaN\n",
    "#df1['busyness'] = np.nan\n",
    "# Replace all values in the 'busyness' column with 100 to test the prediction\n",
    "df['busyness'] = 100\n",
    "\n",
    "# making my df a timeseriesdf\n",
    "dfts= TimeSeriesDataFrame.from_data_frame(\n",
    "    df1,\n",
    "    id_column=\"location\",\n",
    "    timestamp_column=\"datetime\"\n",
    ")\n",
    "print(dfts.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb13e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating leaderboard for all models trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  score_val  pred_time_val  fit_time_marginal  \\\n",
      "0           WeightedEnsemble  -1.419699       3.063145           1.804674   \n",
      "1  TemporalFusionTransformer  -1.421149       2.549684         182.501629   \n",
      "2              SeasonalNaive  -2.120057       0.513461           3.800257   \n",
      "3                        ETS  -5.349771     119.842454           3.847995   \n",
      "4                      Theta  -7.563938      27.076159           4.023075   \n",
      "5                      Naive -22.347831       2.718518           3.900895   \n",
      "\n",
      "   fit_order  \n",
      "0          6  \n",
      "1          5  \n",
      "2          2  \n",
      "3          3  \n",
      "4          4  \n",
      "5          1  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d64d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "Found no cached predictions\n",
      "Prediction order: ['TemporalFusionTransformer', 'SeasonalNaive', 'WeightedEnsemble']\n",
      "Predicting with model TemporalFusionTransformer/W0\n",
      "Predicting with model TemporalFusionTransformer\n",
      "Shortening all time series to at most 2500\n",
      "Predicting with model SeasonalNaive/W0\n",
      "Predicting with model SeasonalNaive\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to scripts/new_taxi/autogluon_manh_taxi/autogluon-m4-hourly/models/cached_predictions.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 mean       0.1       0.2       0.3       0.4  \\\n",
      "item_id timestamp                                                               \n",
      "1       2024-04-01 00:00:00  1.003467  0.978869  0.998763  0.997993  0.993789   \n",
      "        2024-04-01 01:00:00  1.003556  0.975604  0.996856  0.996035  0.994512   \n",
      "        2024-04-01 02:00:00  1.003466  0.975113  0.996011  0.995898  0.994459   \n",
      "        2024-04-01 03:00:00  1.003206  0.975815  0.995812  0.996920  0.994243   \n",
      "        2024-04-01 04:00:00  1.002531  0.976436  0.995994  0.998535  0.993697   \n",
      "...                               ...       ...       ...       ...       ...   \n",
      "104     2024-03-30 07:00:00  1.000832  0.995501  0.997661  0.998966  0.999819   \n",
      "        2024-03-30 08:00:00  1.000931  0.995919  0.997807  0.999130  0.999884   \n",
      "        2024-03-30 09:00:00  1.000924  0.996460  0.998051  0.999213  0.999861   \n",
      "        2024-03-30 10:00:00  1.000815  0.997082  0.998317  0.999263  0.999815   \n",
      "        2024-03-30 11:00:00  1.000736  0.997399  0.998451  0.999277  0.999818   \n",
      "\n",
      "                                  0.5       0.6       0.7       0.8       0.9  \n",
      "item_id timestamp                                                              \n",
      "1       2024-04-01 00:00:00  1.003467  0.996017  0.995604  1.005871  1.013906  \n",
      "        2024-04-01 01:00:00  1.003556  0.994447  0.997787  1.008184  1.009114  \n",
      "        2024-04-01 02:00:00  1.003466  0.993675  0.998982  1.010346  1.011367  \n",
      "        2024-04-01 03:00:00  1.003206  0.993985  0.999658  1.011473  1.019096  \n",
      "        2024-04-01 04:00:00  1.002531  0.994700  0.999251  1.013908  1.034820  \n",
      "...                               ...       ...       ...       ...       ...  \n",
      "104     2024-03-30 07:00:00  1.000832  1.000591  1.001166  1.001418  1.001240  \n",
      "        2024-03-30 08:00:00  1.000931  1.000909  1.001398  1.001990  1.002217  \n",
      "        2024-03-30 09:00:00  1.000924  1.001088  1.001571  1.002628  1.003268  \n",
      "        2024-03-30 10:00:00  1.000815  1.001107  1.001678  1.003108  1.004186  \n",
      "        2024-03-30 11:00:00  1.000736  1.001150  1.001820  1.003338  1.004736  \n",
      "\n",
      "[12672 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = predictor.predict(dfts)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71507a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n"
     ]
    }
   ],
   "source": [
    "plot = predictor.plot(dfts, predictions, quantile_levels=[0.1, 0.9], max_history_length=200, max_num_item_ids=4)\n",
    "plot.savefig(\"test-plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613923b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
