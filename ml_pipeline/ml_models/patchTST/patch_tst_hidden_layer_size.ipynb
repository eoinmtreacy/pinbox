{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a92e073",
   "metadata": {},
   "source": [
    "This notebook combines all features into one large model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f4398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CS\\summer_project\\comp47360-group8\\ml_pipeline\\utils\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..', 'utils'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from ml_tools import add_weekends_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data_evaluation/taxi_trip_data/all_tlc_data_cleaned.parquet')\n",
    "df.rename({'passenger_count':'busyness', 'location':'item_id', 'datetime': 'timestamp'},axis=1, inplace=True)\n",
    "\n",
    "df['day'] = df['timestamp'].dt.day_name().str.lower()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_open = pd.read_csv(\"../../data_preparation/taxi_location_num_businesses_open/taxi_location_num_businesses_open.csv\")\n",
    "df_open.rename({'location':'item_id'},axis=1, inplace=True)\n",
    "df = df.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "df.fillna({'alcohol':0, 'food':0, 'leisure':0}, inplace=True)\n",
    "df.drop(['day', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "df_wth = pd.read_csv(\"../../data_evaluation/weather_meteostat/meteostat_weather.csv\")\n",
    "df_wth.rename({'time':'timestamp'}, axis=1,inplace=True)\n",
    "df_wth['timestamp'] = df_wth['timestamp'].astype('datetime64[us]')\n",
    "df_wth['timestamp'] = pd.to_datetime(df_wth['timestamp'])\n",
    "df_wth['coco'] = df_wth['coco'].astype('category')\n",
    "df_wth.sort_values(by=['timestamp'])\n",
    "df = df.join(df_wth.set_index('timestamp'), on='timestamp', how='left')\n",
    "\n",
    "static_features_df = pd.read_csv(\"../../data_evaluation/taxi_trip_data/taxi_zone_lookup.csv\")\n",
    "static_features_df.rename({'LocationID': 'item_id'}, axis=1, inplace=True)\n",
    "\n",
    "data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df = static_features_df\n",
    ")\n",
    "add_weekends_holidays(data)\n",
    "\n",
    "prediction_length = 3 * 30 * 24 # 3 months prediction window\n",
    "train_data, test_data = data.train_test_split(prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b2e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_hidden_layer_size_32_model_files'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hidden layer size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       6.53 GB / 15.90 GB (41.0%)\n",
      "Disk Space Avail:   2114.60 GB / 2794.50 GB (75.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192, 'd_model': 32}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-14 17:50:53\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8677       = Validation score (-MASE)\n",
      "\t290.90  s     = Training runtime\n",
      "\t16.49   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 311.11 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.867656      16.488164         290.904537          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_hidden_layer_size_64_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       6.96 GB / 15.90 GB (43.8%)\n",
      "Disk Space Avail:   2113.76 GB / 2794.50 GB (75.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192, 'd_model': 64}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hidden layer size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-14 17:56:58\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8640       = Validation score (-MASE)\n",
      "\t874.20  s     = Training runtime\n",
      "\t16.85   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 898.70 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.864036      16.852797         874.204353          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_hidden_layer_size_128_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       6.37 GB / 15.90 GB (40.1%)\n",
      "Disk Space Avail:   2109.20 GB / 2794.50 GB (75.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192, 'd_model': 128}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hidden layer size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-14 18:12:52\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\tWarning: Exception caused PatchTST to fail during training... Skipping this model.\n",
      "\tCUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacty of 12.00 GiB of which 468.91 MiB is free. Of the allocated memory 9.52 GiB is allocated by PyTorch, and 180.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Not fitting ensemble as no models were successfully trained.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 28.14 s\n",
      "Trainer has no fit models that can predict.\n",
      "Warning: No models were trained during fit. Resulting leaderboard will be empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [model, score_val, pred_time_val, fit_time_marginal, fit_order]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mfit(train_data,\n\u001b[0;32m     17\u001b[0m                                 hyperparameters\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatchTST\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     18\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m192\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m                                 \n\u001b[0;32m     23\u001b[0m                                 )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictor\u001b[38;5;241m.\u001b[39mleaderboard())\n\u001b[1;32m---> 25\u001b[0m mase_values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:905\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.evaluate\u001b[1;34m(self, data, model, metrics, display, use_cache)\u001b[0m\n\u001b[0;32m    903\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_prepare_data_frame(data)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_for_evaluation(data)\n\u001b[1;32m--> 905\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display:\n\u001b[0;32m    907\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluations on test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\learner.py:212\u001b[0m, in \u001b[0;36mTimeSeriesLearner.evaluate\u001b[1;34m(self, data, model, metrics, use_cache)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    206\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     use_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    211\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:938\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.evaluate\u001b[1;34m(self, data, model, metrics, use_cache)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    933\u001b[0m     use_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    935\u001b[0m     past_data, known_covariates \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_model_inputs_for_scoring(\n\u001b[0;32m    936\u001b[0m         prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length, known_covariates_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mknown_covariates\n\u001b[0;32m    937\u001b[0m     )\n\u001b[1;32m--> 938\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# a single metric is provided\u001b[39;00m\n\u001b[0;32m    940\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m [metrics]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:891\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.predict\u001b[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    884\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    890\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeSeriesDataFrame:\n\u001b[1;32m--> 891\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m     model_pred_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_pred_dict(\n\u001b[0;32m    893\u001b[0m         model_names\u001b[38;5;241m=\u001b[39m[model_name],\n\u001b[0;32m    894\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    897\u001b[0m         random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    898\u001b[0m     )\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_pred_dict[model_name]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:868\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._get_model_for_prediction\u001b[1;34m(self, model, verbose)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 868\u001b[0m         best_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;241m=\u001b[39m best_model_name\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:394\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.get_model_best\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "# setting the frequency to h since the data is grouped/collected hourly,\n",
    "# # added relative path \n",
    "mase_values = []\n",
    "for hidden_layer_size in [32, 64, 128]:\n",
    "    model_name = f\"patch_tst_hidden_layer_size_{hidden_layer_size}\" + \"_model_files\"\n",
    "\n",
    "    print(\"Evaluating hidden layer size:\", hidden_layer_size)\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        freq='h',\n",
    "        target=\"busyness\",\n",
    "        eval_metric=\"MASE\",\n",
    "        prediction_length=prediction_length,\n",
    "        path=model_name,\n",
    "        known_covariates_names=['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', 'dwpt', 'rhum', 'prcp', 'pres', 'coco']\n",
    "    )\n",
    "    predictions = predictor.fit(train_data,\n",
    "                                    hyperparameters= {\"PatchTST\": {\n",
    "                                        \"context_length\":192,\n",
    "                                        \"d_model\":hidden_layer_size\n",
    "                                    }}\n",
    "                                    # excluded_model_types=[\"Chronos\", \"RecursiveTabular\", \"NPTS\", \"DeepAR\", \"AutoARIMA\", \"AutoETS\", \"DirectTabular\", \"DeepAR\"]\n",
    "                                    \n",
    "                                    )\n",
    "    print(predictor.leaderboard())\n",
    "    mase_values += [predictor.evaluate(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da310d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MASE': -1.3846876062081266}, {'MASE': -1.3622890570974713}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mase_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f024d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\utils\\forecast.py:34: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  offset = pd.tseries.frequencies.to_offset(freq)\n"
     ]
    }
   ],
   "source": [
    "future_index = get_forecast_horizon_index_ts_dataframe(train_data, prediction_length=prediction_length, freq='H')\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\").to_series()\n",
    "known_covariates = pd.DataFrame(index=future_index)\n",
    "known_covariates['day'] = future_timestamps.dt.day_name().str.lower().values\n",
    "known_covariates['hour'] = future_timestamps.dt.hour.to_list()\n",
    "known_covariates = known_covariates.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "known_covariates = known_covariates.join(df_wth.set_index(\"timestamp\"), on='timestamp', how='left')\n",
    "add_weekends_holidays(known_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f480203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
