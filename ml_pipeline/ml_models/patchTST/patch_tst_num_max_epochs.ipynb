{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a92e073",
   "metadata": {},
   "source": [
    "This notebook combines all features into one large model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f4398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CS\\summer_project\\comp47360-group8\\ml_pipeline\\utils\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..', 'utils'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from ml_tools import add_weekends_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data_evaluation/taxi_trip_data/all_tlc_data_cleaned.parquet')\n",
    "df.rename({'passenger_count':'busyness', 'location':'item_id', 'datetime': 'timestamp'},axis=1, inplace=True)\n",
    "\n",
    "df['day'] = df['timestamp'].dt.day_name().str.lower()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_open = pd.read_csv(\"../../data_preparation/taxi_location_num_businesses_open/taxi_location_num_businesses_open.csv\")\n",
    "df_open.rename({'location':'item_id'},axis=1, inplace=True)\n",
    "df = df.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "df.fillna({'alcohol':0, 'food':0, 'leisure':0}, inplace=True)\n",
    "df.drop(['day', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "df_wth = pd.read_csv(\"../../data_evaluation/weather_meteostat/meteostat_weather.csv\")\n",
    "df_wth.rename({'time':'timestamp'}, axis=1,inplace=True)\n",
    "df_wth['timestamp'] = df_wth['timestamp'].astype('datetime64[us]')\n",
    "df_wth['timestamp'] = pd.to_datetime(df_wth['timestamp'])\n",
    "df_wth['coco'] = df_wth['coco'].astype('category')\n",
    "df_wth.sort_values(by=['timestamp'])\n",
    "df = df.join(df_wth.set_index('timestamp'), on='timestamp', how='left')\n",
    "\n",
    "static_features_df = pd.read_csv(\"../../data_evaluation/taxi_trip_data/taxi_zone_lookup.csv\")\n",
    "static_features_df.rename({'LocationID': 'item_id'}, axis=1, inplace=True)\n",
    "\n",
    "data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df = static_features_df\n",
    ")\n",
    "add_weekends_holidays(data)\n",
    "\n",
    "prediction_length = 3 * 30 * 24 # 3 months prediction window\n",
    "train_data, test_data = data.train_test_split(prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b2e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_max_epochs_100_model_files'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patch_tst_max_epochs_100_model_files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       4.93 GB / 15.90 GB (31.0%)\n",
      "Disk Space Avail:   2099.36 GB / 2794.50 GB (75.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192,\n",
      "                                  'max_epochs': 100,\n",
      "                                  'num_encoder_layers': 4}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-15 18:44:07\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8638       = Validation score (-MASE)\n",
      "\t319.93  s     = Training runtime\n",
      "\t16.68   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 341.92 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.863805      16.684095         319.925678          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_max_epochs_200_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       5.58 GB / 15.90 GB (35.1%)\n",
      "Disk Space Avail:   2098.53 GB / 2794.50 GB (75.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192,\n",
      "                                  'max_epochs': 200,\n",
      "                                  'num_encoder_layers': 4}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patch_tst_max_epochs_200_model_files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-15 18:50:44\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8638       = Validation score (-MASE)\n",
      "\t307.22  s     = Training runtime\n",
      "\t16.14   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 327.53 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.863805      16.135371         307.223584          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_max_epochs_400_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       5.00 GB / 15.90 GB (31.5%)\n",
      "Disk Space Avail:   2097.69 GB / 2794.50 GB (75.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192,\n",
      "                                  'max_epochs': 400,\n",
      "                                  'num_encoder_layers': 4}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patch_tst_max_epochs_400_model_files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-15 18:57:03\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8638       = Validation score (-MASE)\n",
      "\t306.49  s     = Training runtime\n",
      "\t16.11   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 326.87 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.863805      16.106785         306.491518          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n"
     ]
    }
   ],
   "source": [
    "# setting the frequency to h since the data is grouped/collected hourly,\n",
    "# # added relative path \n",
    "mase_values = []\n",
    "for max_epochs in [100, 200, 400]:\n",
    "    model_name = f\"patch_tst_max_epochs_{max_epochs}\" + \"_model_files\"\n",
    "\n",
    "    print(\"Evaluating\", model_name)\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        freq='h',\n",
    "        target=\"busyness\",\n",
    "        eval_metric=\"MASE\",\n",
    "        prediction_length=prediction_length,\n",
    "        path=model_name,\n",
    "        known_covariates_names=['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', 'dwpt', 'rhum', 'prcp', 'pres', 'coco']\n",
    "    )\n",
    "    predictions = predictor.fit(train_data,\n",
    "                                    # num_val_windows=max_epochs,\n",
    "                                    hyperparameters= {\"PatchTST\": {\n",
    "                                        \"context_length\":192,\n",
    "                                        \"num_encoder_layers\":4,\n",
    "                                        \"max_epochs\":max_epochs\n",
    "                                    }}\n",
    "                                    # excluded_model_types=[\"Chronos\", \"RecursiveTabular\", \"NPTS\", \"DeepAR\", \"AutoARIMA\", \"AutoETS\", \"DirectTabular\", \"DeepAR\"]\n",
    "                                    \n",
    "                                    )\n",
    "    print(predictor.leaderboard())\n",
    "    mase_values += [predictor.evaluate(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da310d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MASE': -1.3139385859470363},\n",
       " {'MASE': -1.3139385859470363},\n",
       " {'MASE': -1.3139385859470363}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mase_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f024d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\utils\\forecast.py:34: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  offset = pd.tseries.frequencies.to_offset(freq)\n"
     ]
    }
   ],
   "source": [
    "future_index = get_forecast_horizon_index_ts_dataframe(train_data, prediction_length=prediction_length, freq='H')\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\").to_series()\n",
    "known_covariates = pd.DataFrame(index=future_index)\n",
    "known_covariates['day'] = future_timestamps.dt.day_name().str.lower().values\n",
    "known_covariates['hour'] = future_timestamps.dt.hour.to_list()\n",
    "known_covariates = known_covariates.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "known_covariates = known_covariates.join(df_wth.set_index(\"timestamp\"), on='timestamp', how='left')\n",
    "add_weekends_holidays(known_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f480203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
