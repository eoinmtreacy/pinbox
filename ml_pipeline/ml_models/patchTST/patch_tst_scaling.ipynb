{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a92e073",
   "metadata": {},
   "source": [
    "This notebook combines all features into one large model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f4398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CS\\summer_project\\comp47360-group8\\ml_pipeline\\utils\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..', 'utils'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from ml_tools import add_weekends_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data_evaluation/taxi_trip_data/all_tlc_data_cleaned.parquet')\n",
    "df.rename({'passenger_count':'busyness', 'location':'item_id', 'datetime': 'timestamp'},axis=1, inplace=True)\n",
    "\n",
    "df['day'] = df['timestamp'].dt.day_name().str.lower()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_open = pd.read_csv(\"../../data_preparation/taxi_location_num_businesses_open/taxi_location_num_businesses_open.csv\")\n",
    "df_open.rename({'location':'item_id'},axis=1, inplace=True)\n",
    "df = df.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "df.fillna({'alcohol':0, 'food':0, 'leisure':0}, inplace=True)\n",
    "df.drop(['day', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "df_wth = pd.read_csv(\"../../data_evaluation/weather_meteostat/meteostat_weather.csv\")\n",
    "df_wth.rename({'time':'timestamp'}, axis=1,inplace=True)\n",
    "df_wth['timestamp'] = df_wth['timestamp'].astype('datetime64[us]')\n",
    "df_wth['timestamp'] = pd.to_datetime(df_wth['timestamp'])\n",
    "df_wth['coco'] = df_wth['coco'].astype('category')\n",
    "df_wth.sort_values(by=['timestamp'])\n",
    "df = df.join(df_wth.set_index('timestamp'), on='timestamp', how='left')\n",
    "\n",
    "static_features_df = pd.read_csv(\"../../data_evaluation/taxi_trip_data/taxi_zone_lookup.csv\")\n",
    "static_features_df.rename({'LocationID': 'item_id'}, axis=1, inplace=True)\n",
    "\n",
    "data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    static_features_df = static_features_df\n",
    ")\n",
    "add_weekends_holidays(data)\n",
    "\n",
    "prediction_length = 3 * 30 * 24 # 3 months prediction window\n",
    "train_data, test_data = data.train_test_split(prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b2e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"patch_tst_val_windows_mean_model_files\"\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_val_windows_mean_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       6.08 GB / 15.90 GB (38.2%)\n",
      "Disk Space Avail:   2094.83 GB / 2794.50 GB (75.0%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192,\n",
      "                                  'num_encoder_layers': 4,\n",
      "                                  'scaling': 'mean'}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating scaling: mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-15 19:22:12\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.8638       = Validation score (-MASE)\n",
      "\t300.70  s     = Training runtime\n",
      "\t16.35   s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['PatchTST']\n",
      "Total runtime: 320.61 s\n",
      "Best model: PatchTST\n",
      "Best model score: -0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  score_val  pred_time_val  fit_time_marginal  fit_order\n",
      "0  PatchTST  -0.863805      16.347237         300.697383          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Model not specified in predict, will default to the model with the best validation score: PatchTST\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"patch_tst_val_windows_std_model_files\"\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'patch_tst_val_windows_std_model_files'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       5.61 GB / 15.90 GB (35.3%)\n",
      "Disk Space Avail:   2094.83 GB / 2794.50 GB (75.0%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'PatchTST': {'context_length': 192,\n",
      "                                  'num_encoder_layers': 4,\n",
      "                                  'scaling': 'std'}},\n",
      " 'known_covariates_names': ['food',\n",
      "                            'alcohol',\n",
      "                            'leisure',\n",
      "                            'weekend',\n",
      "                            'holiday',\n",
      "                            'temp',\n",
      "                            'dwpt',\n",
      "                            'rhum',\n",
      "                            'prcp',\n",
      "                            'pres',\n",
      "                            'coco'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2160,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'busyness',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating scaling: std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 6826363 rows (NaN fraction=1.0%), 261 time series. Median time series length is 26303 (min=9291, max=26305). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'busyness'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['coco']\n",
      "\t\tcontinuous (float): ['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', ...]\n",
      "\tstatic_features:\n",
      "\t\tcategorical:        ['Borough', 'Zone', 'service_zone']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-07-15 19:28:07\n",
      "Models that will be trained: ['PatchTST']\n",
      "Training timeseries model PatchTST. \n",
      "\tWarning: Exception caused PatchTST to fail during training... Skipping this model.\n",
      "\tExpected parameter df (Tensor of shape (64, 2160)) of distribution Chi2() to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "Not fitting ensemble as no models were successfully trained.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 145.31 s\n",
      "Trainer has no fit models that can predict.\n",
      "Warning: No models were trained during fit. Resulting leaderboard will be empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [model, score_val, pred_time_val, fit_time_marginal, fit_order]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency 'h'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mfit(train_data,\n\u001b[0;32m     17\u001b[0m                                 \u001b[38;5;66;03m# num_val_windows=scaling,\u001b[39;00m\n\u001b[0;32m     18\u001b[0m                                 hyperparameters\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatchTST\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                 \n\u001b[0;32m     25\u001b[0m                                 )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictor\u001b[38;5;241m.\u001b[39mleaderboard())\n\u001b[1;32m---> 27\u001b[0m mase_values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:905\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.evaluate\u001b[1;34m(self, data, model, metrics, display, use_cache)\u001b[0m\n\u001b[0;32m    903\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_prepare_data_frame(data)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_for_evaluation(data)\n\u001b[1;32m--> 905\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display:\n\u001b[0;32m    907\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluations on test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\learner.py:212\u001b[0m, in \u001b[0;36mTimeSeriesLearner.evaluate\u001b[1;34m(self, data, model, metrics, use_cache)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    206\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     use_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    211\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:938\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.evaluate\u001b[1;34m(self, data, model, metrics, use_cache)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    933\u001b[0m     use_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    935\u001b[0m     past_data, known_covariates \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_model_inputs_for_scoring(\n\u001b[0;32m    936\u001b[0m         prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length, known_covariates_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mknown_covariates\n\u001b[0;32m    937\u001b[0m     )\n\u001b[1;32m--> 938\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# a single metric is provided\u001b[39;00m\n\u001b[0;32m    940\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m [metrics]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:891\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.predict\u001b[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    884\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    890\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeSeriesDataFrame:\n\u001b[1;32m--> 891\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m     model_pred_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_pred_dict(\n\u001b[0;32m    893\u001b[0m         model_names\u001b[38;5;241m=\u001b[39m[model_name],\n\u001b[0;32m    894\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    897\u001b[0m         random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    898\u001b[0m     )\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_pred_dict[model_name]\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:868\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._get_model_for_prediction\u001b[1;34m(self, model, verbose)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 868\u001b[0m         best_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;241m=\u001b[39m best_model_name\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:394\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.get_model_best\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "# setting the frequency to h since the data is grouped/collected hourly,\n",
    "# # added relative path \n",
    "mase_values = []\n",
    "for scaling in [\"mean\", \"std\"]:\n",
    "    model_name = f\"patch_tst_val_windows_{scaling}\" + \"_model_files\"\n",
    "\n",
    "    print(\"Evaluating scaling:\", scaling)\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        freq='h',\n",
    "        target=\"busyness\",\n",
    "        eval_metric=\"MASE\",\n",
    "        prediction_length=prediction_length,\n",
    "        path=model_name,\n",
    "        known_covariates_names=['food', 'alcohol', 'leisure', 'weekend', 'holiday', 'temp', 'dwpt', 'rhum', 'prcp', 'pres', 'coco']\n",
    "    )\n",
    "    predictions = predictor.fit(train_data,\n",
    "                                    # num_val_windows=scaling,\n",
    "                                    hyperparameters= {\"PatchTST\": {\n",
    "                                        \"context_length\":192,\n",
    "                                        \"num_encoder_layers\":4,\n",
    "                                        \"scaling\": scaling\n",
    "                                    }}\n",
    "                                    # excluded_model_types=[\"Chronos\", \"RecursiveTabular\", \"NPTS\", \"DeepAR\", \"AutoARIMA\", \"AutoETS\", \"DirectTabular\", \"DeepAR\"]\n",
    "                                    \n",
    "                                    )\n",
    "    print(predictor.leaderboard())\n",
    "    mase_values += [predictor.evaluate(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da310d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MASE': -1.3139385859470363},\n",
       " {'MASE': -1.3035399995859513},\n",
       " {'MASE': -1.3193764219092188},\n",
       " {'MASE': -1.311796962864003}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mase_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f024d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\miniconda3\\envs\\comp47360_autogluon\\lib\\site-packages\\autogluon\\timeseries\\utils\\forecast.py:34: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  offset = pd.tseries.frequencies.to_offset(freq)\n"
     ]
    }
   ],
   "source": [
    "future_index = get_forecast_horizon_index_ts_dataframe(train_data, prediction_length=prediction_length, freq='H')\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\").to_series()\n",
    "known_covariates = pd.DataFrame(index=future_index)\n",
    "known_covariates['day'] = future_timestamps.dt.day_name().str.lower().values\n",
    "known_covariates['hour'] = future_timestamps.dt.hour.to_list()\n",
    "known_covariates = known_covariates.join(df_open.set_index(['day', 'hour', 'item_id']), on=['day', 'hour', 'item_id'])\n",
    "known_covariates = known_covariates.join(df_wth.set_index(\"timestamp\"), on='timestamp', how='left')\n",
    "add_weekends_holidays(known_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f480203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
